{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed5ce27-a839-4547-9e4e-38543fa59348",
   "metadata": {},
   "source": [
    "# U-Net Model - Orbital Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7725294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from torchmetrics.segmentation import GeneralizedDiceScore\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bad9b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Model Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9cd663",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f212539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BenedictShaw/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/BenedictShaw/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet34 model\n",
    "resnet34 = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c32ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34.conv1 = nn.Conv2d(\n",
    "    in_channels=6,   # 6 for pre + post RGB images\n",
    "    out_channels=64,\n",
    "    kernel_size=7,\n",
    "    stride=2,\n",
    "    padding=3,\n",
    "    bias=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16543ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f04a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all parameters in the pretrained model, other than those in the first layer (that have been trained)\n",
    "for name, param in resnet34.named_parameters():\n",
    "    if name.startswith('conv1'):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ea226",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555b273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function defining the convolution block\n",
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb025aa",
   "metadata": {},
   "source": [
    "### Combining the Decoder to Form the U-Net\n",
    "\n",
    "The **forward()** function defines the data flow through your model — it's how the model transforms input data into an output using its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0e520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the U-Net model class\n",
    "class UNetModel(nn.Module):\n",
    "    def __init__(self, n_classes=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder (modified for 6-channel input)\n",
    "        self.encoder = resnet34\n",
    "\n",
    "        # Decoder blocks with transpose convolutions\n",
    "        self.up5 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)\n",
    "        self.dec5 = conv_block(512 + 256, 256)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.dec4 = conv_block(256 + 128, 128)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(128 + 64, 64)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(64 + 64, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder.relu(self.encoder.bn1(self.encoder.conv1(x)))\n",
    "        e2 = self.encoder.layer1(self.encoder.maxpool(e1))\n",
    "        e3 = self.encoder.layer2(e2)\n",
    "        e4 = self.encoder.layer3(e3)\n",
    "        e5 = self.encoder.layer4(e4)\n",
    "\n",
    "        d5 = self.dec5(torch.cat([self.up5(e5), e4], dim=1))\n",
    "        d4 = self.dec4(torch.cat([self.up4(d5), e3], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e2], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e1], dim=1))\n",
    "\n",
    "        out = self.final_conv(d2)\n",
    "        return F.interpolate(out, size=(224, 224), mode='bilinear', align_corners=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bfea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      " ConvTranspose2d-123          [-1, 512, 14, 14]       1,049,088\n",
      "          Conv2d-124          [-1, 256, 14, 14]       1,769,728\n",
      "            ReLU-125          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-126          [-1, 256, 14, 14]             512\n",
      "          Conv2d-127          [-1, 256, 14, 14]         590,080\n",
      "            ReLU-128          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-129          [-1, 256, 14, 14]             512\n",
      " ConvTranspose2d-130          [-1, 256, 28, 28]         262,400\n",
      "          Conv2d-131          [-1, 128, 28, 28]         442,496\n",
      "            ReLU-132          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-133          [-1, 128, 28, 28]             256\n",
      "          Conv2d-134          [-1, 128, 28, 28]         147,584\n",
      "            ReLU-135          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-136          [-1, 128, 28, 28]             256\n",
      " ConvTranspose2d-137          [-1, 128, 56, 56]          65,664\n",
      "          Conv2d-138           [-1, 64, 56, 56]         110,656\n",
      "            ReLU-139           [-1, 64, 56, 56]               0\n",
      "     BatchNorm2d-140           [-1, 64, 56, 56]             128\n",
      "          Conv2d-141           [-1, 64, 56, 56]          36,928\n",
      "            ReLU-142           [-1, 64, 56, 56]               0\n",
      "     BatchNorm2d-143           [-1, 64, 56, 56]             128\n",
      " ConvTranspose2d-144         [-1, 64, 112, 112]          16,448\n",
      "          Conv2d-145         [-1, 64, 112, 112]          73,792\n",
      "            ReLU-146         [-1, 64, 112, 112]               0\n",
      "     BatchNorm2d-147         [-1, 64, 112, 112]             128\n",
      "          Conv2d-148         [-1, 64, 112, 112]          36,928\n",
      "            ReLU-149         [-1, 64, 112, 112]               0\n",
      "     BatchNorm2d-150         [-1, 64, 112, 112]             128\n",
      "          Conv2d-151          [-1, 5, 112, 112]             325\n",
      "================================================================\n",
      "Total params: 25,898,245\n",
      "Trainable params: 4,622,981\n",
      "Non-trainable params: 21,275,264\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.15\n",
      "Forward/backward pass size (MB): 161.07\n",
      "Params size (MB): 98.79\n",
      "Estimated Total Size (MB): 261.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = UNetModel(n_classes=5)\n",
    "summary(model, input_size=(6, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf238d2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "*Concatenate “pre” and “post” 3-channel disaster images from each pair into a single tensor with 6 channels and use it as an input to the U-Net model. The 'target' is the single channel post-disaster mask.*\n",
    "\n",
    "**NOTE: designed to retrieve images from local file**\n",
    "\n",
    "Here, we are using the Pytorch Dataset class to control the loading of image data (features + labels) and the transformations that are applied (concatonation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4adb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1032824, 1: 2352, 2: 4079, 3: 9321}\n"
     ]
    }
   ],
   "source": [
    "#Testing image to tensor\n",
    "img_path = \"../data/processed/masks/hurricane-florence_00000048_post_disaster_mask.png\"\n",
    "img = Image.open(img_path)\n",
    "mask_np = np.array(img)\n",
    "mask_tensor = torch.from_numpy(mask_np).long()\n",
    "unique_vals, counts = torch.unique(mask_tensor, return_counts=True)\n",
    "print(dict(zip(unique_vals.tolist(), counts.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cacc3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir_test = \"../data/processed/split/train/images\"\n",
    "len(os.listdir(img_dir_test))\n",
    "mask_dir_test = \"../data/processed/split/train/masks\"\n",
    "len(os.listdir(mask_dir_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bbb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MaskTransform at 0x13a7975e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying a class for mask transformation (png to tensor)\n",
    "class MaskTransform:\n",
    "    def __init__(self, size=(224, 224)):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, mask):\n",
    "        # Resize using NEAREST interpolation to preserve class values\n",
    "        mask = TF.resize(mask, self.size, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        # Convert to LongTensor of class indices\n",
    "        return torch.as_tensor(np.array(mask), dtype=torch.long)\n",
    "\n",
    "MaskTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7872f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_transform = MaskTransform(size=(224, 224))\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, mask_transform=None):\n",
    "        self.image_dir = os.path.join(root_dir, \"images\")\n",
    "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        # Find all base mask IDs (e.g. \"hurricane-florence_00000000\")\n",
    "        all_mask_files = os.listdir(self.mask_dir)\n",
    "        self.ids = sorted(list(set(\n",
    "            f.replace(\"_pre_disaster_mask.png\", \"\").replace(\"_post_disaster_mask.png\", \"\")\n",
    "            for f in all_mask_files\n",
    "            if f.endswith(\".png\")\n",
    "        )))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.ids[idx]\n",
    "\n",
    "        # File paths\n",
    "        pre_path = os.path.join(self.image_dir, f\"{image_id}_pre_disaster.png\")\n",
    "        post_path = os.path.join(self.image_dir, f\"{image_id}_post_disaster.png\")\n",
    "        post_mask_path = os.path.join(self.mask_dir, f\"{image_id}_post_disaster_mask.png\")\n",
    "\n",
    "        # Open images\n",
    "        pre_img = Image.open(pre_path)\n",
    "        post_img = Image.open(post_path)\n",
    "        post_mask = Image.open(post_mask_path)\n",
    "\n",
    "        # Apply image transforms\n",
    "        if self.transform:\n",
    "            pre_img = self.transform(pre_img)\n",
    "            post_img = self.transform(post_img)\n",
    "\n",
    "        image = torch.cat([pre_img, post_img], dim=0)  # shape: [6, H, W]\n",
    "\n",
    "        # Apply mask transforms\n",
    "        if self.mask_transform:\n",
    "            post_mask = self.mask_transform(post_mask)\n",
    "\n",
    "        return image, post_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb61be7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20\n",
       "0    216\n",
       "3      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_mask = mask_transform(Image.open(\"../data/processed/masks/hurricane-florence_00000048_post_disaster_mask.png\"))\n",
    "df = pd.DataFrame(post_mask)\n",
    "df[20].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcec9d3",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4ae8526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the torch cache, which may slow the training process\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb575a",
   "metadata": {},
   "source": [
    "### Loading in the train, val and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "720c37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PrimaryDataset(\"../data/processed/split/train/\", transform=img_transform, mask_transform=mask_transform)\n",
    "val_dataset = PrimaryDataset(\"../data/processed/split/val/\", transform=img_transform, mask_transform=mask_transform)\n",
    "test_dataset = PrimaryDataset(\"../data/processed/split/test/\", transform=img_transform, mask_transform=mask_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcefe43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              pin_memory=False,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            pin_memory=False,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                            pin_memory=False,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f18076",
   "metadata": {},
   "source": [
    "### Model initialisation, and defining model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eea2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the model\n",
    "model = UNetModel(n_classes=5).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33b9168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Generalised Dice Score function (inputs --> preds, target)\n",
    "gds = GeneralizedDiceScore(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_dice(y_pred, mask, criterion, gds):\n",
    "    if mask.dim() == 4:\n",
    "        mask = torch.argmax(mask, dim=1)  # [B, H, W]\n",
    "\n",
    "    loss = criterion(y_pred, mask)\n",
    "\n",
    "    y_prob = F.softmax(y_pred, dim=1)\n",
    "    mask_onehot = one_hot(mask, num_classes=y_pred.shape[1]).permute(0, 3, 1, 2)\n",
    "\n",
    "    dice = gds(y_prob, mask_onehot)\n",
    "\n",
    "    return loss, dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f3c1e",
   "metadata": {},
   "source": [
    "### The training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "520099ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m loss, dice \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss_and_dice\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m, in \u001b[0;36mcompute_loss_and_dice\u001b[0;34m(y_pred, mask, criterion, gds)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m      3\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(mask, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [B, H, W]\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m mask_onehot \u001b[38;5;241m=\u001b[39m one_hot(mask, num_classes\u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m dice \u001b[38;5;241m=\u001b[39m gds(y_pred, mask_onehot)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/loss.py:1297\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "train_losses = []\n",
    "train_dcs = []\n",
    "val_losses = []\n",
    "val_dcs = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    train_running_dc = 0\n",
    "\n",
    "    for idx, img_mask in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n",
    "        img = img_mask[0].float().to(device)\n",
    "        mask = img_mask[1].float().to(device)\n",
    "\n",
    "        y_pred = model(img)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, dice = compute_loss_and_dice(y_pred, mask, criterion, gds)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "        train_running_dc += dice.item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "    train_dc = train_running_dc / (idx + 1)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_dcs.append(train_dc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, img_mask in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n",
    "            img = img_mask[0].float().to(device)\n",
    "            mask = img_mask[1].float().to(device)\n",
    "\n",
    "            y_pred = model(img)\n",
    "            loss, dice = compute_loss_and_dice(y_pred, mask, criterion, gds)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            val_running_dc += dice.item()\n",
    "\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "        val_dc = val_running_dc / (idx + 1)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_dcs.append(val_dc)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Training Loss EPOCH {epoch + 1}: {train_loss:.4f}\")\n",
    "    print(f\"Training DICE EPOCH {epoch + 1}: {train_dc:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Validation Loss EPOCH {epoch + 1}: {val_loss:.4f}\")\n",
    "    print(f\"Validation DICE EPOCH {epoch + 1}: {val_dc:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89c3d173",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_list, val_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(ticks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/matplotlib/pyplot.py:3838\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3832\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3836\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3837\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_list = list(range(1, EPOCHS + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_list, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_list, val_losses, label='Validation Loss')\n",
    "plt.xticks(ticks=list(range(1, EPOCHS + 1, 1)))\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_list, train_dcs, label='Training DICE')\n",
    "plt.plot(epochs_list, val_dcs, label='Validation DICE')\n",
    "plt.xticks(ticks=list(range(1, EPOCHS + 1, 1)))\n",
    "plt.title('DICE Coefficient over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('DICE')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb402e4",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "27ea30da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m mask \u001b[38;5;241m=\u001b[39m img_mask[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[0;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m dc \u001b[38;5;241m=\u001b[39m gds(y_pred, mask)\n\u001b[1;32m     13\u001b[0m test_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/modules/loss.py:1297\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/orbital_response/lib/python3.10/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 4"
     ]
    }
   ],
   "source": [
    "test_running_loss = 0\n",
    "test_running_dc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, img_mask in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n",
    "        img = img_mask[0].float().to(device)\n",
    "        mask = img_mask[1].float().to(device)\n",
    "\n",
    "        y_pred = model(img)\n",
    "        loss = criterion(y_pred, mask)\n",
    "        dc = gds(y_pred, mask)\n",
    "\n",
    "        test_running_loss += loss.item()\n",
    "        test_running_dc += dc.item()\n",
    "\n",
    "    test_loss = test_running_loss / (idx + 1)\n",
    "    test_dc = test_running_dc / (idx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212fab2",
   "metadata": {},
   "source": [
    "## Conversion of Output Mask to RGB .png File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a510e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbital_response",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
