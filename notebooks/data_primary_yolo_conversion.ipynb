{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37f3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Processing split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying labels for train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214/214 [00:00<00:00, 2481.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Processing split: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying labels for val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 3378.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Processing split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying labels for test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 3041.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "ROOT_DIR = Path(\"../data/data_primary/processed/split\")\n",
    "LABEL_SOURCE_DIR = Path(\"../data/data_primary/labels\")  # JSON labels folder\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\nProcessing split: {split}\")\n",
    "\n",
    "    split_dir = ROOT_DIR / split\n",
    "    image_dir = split_dir / \"images\"\n",
    "    label_dir = split_dir / \"labels\"\n",
    "\n",
    "    # Create labels directory if not exists\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through post-disaster images only\n",
    "    image_files = list(image_dir.glob(\"*_post_disaster.png\"))\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=f\"Copying labels for {split}\"):\n",
    "        stem = img_path.stem  # e.g. hurricane-florence_00000000_post_disaster\n",
    "        label_name = f\"{stem}.json\"\n",
    "        label_source_path = LABEL_SOURCE_DIR / label_name\n",
    "        label_dest_path = label_dir / label_name\n",
    "\n",
    "        if label_source_path.exists():\n",
    "            shutil.copy(label_source_path, label_dest_path)\n",
    "        else:\n",
    "            print(f\"Label not found for: {img_path.name}\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219790d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214/214 [00:00<00:00, 2731.93it/s]\n",
      "Converting val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 3283.95it/s]\n",
      "Converting test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 3131.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… YOLO label conversion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "SOURCE_ROOT = Path(\"../data/data_primary/processed/split\")\n",
    "DEST_ROOT = Path(\"../data/data_primary_yolo\")\n",
    "CLASS_MAPPING = {\n",
    "    'no-damage': 1,\n",
    "    'minor-damage': 0,\n",
    "    'major-damage': 0,\n",
    "    'destroyed': 0\n",
    "}\n",
    "IMAGE_EXTENSION = \".png\"\n",
    "\n",
    "# === Create Output Folder Structure ===\n",
    "for split in SPLITS:\n",
    "    (DEST_ROOT / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Main Processing Loop ===\n",
    "for split in SPLITS:\n",
    "    label_dir = SOURCE_ROOT / split / \"labels\"\n",
    "    image_dir = SOURCE_ROOT / split / \"images\"\n",
    "    output_dir = DEST_ROOT / \"labels\" / split\n",
    "\n",
    "    if not label_dir.exists():\n",
    "        continue\n",
    "\n",
    "    label_files = list(label_dir.glob(\"*.json\"))\n",
    "\n",
    "    for label_path in tqdm(label_files, desc=f\"Converting {split}\"):\n",
    "        base_stem = label_path.stem\n",
    "        image_path = image_dir / f\"{base_stem}{IMAGE_EXTENSION}\"\n",
    "\n",
    "        if not image_path.exists():\n",
    "            continue\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        features = data.get(\"features\", [])\n",
    "        if not isinstance(features, list):\n",
    "            continue\n",
    "\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        label_lines = []\n",
    "\n",
    "        for feature in features:\n",
    "            if not isinstance(feature, dict):\n",
    "                continue\n",
    "\n",
    "            props = feature.get(\"properties\", {})\n",
    "            geom = shape(feature.get(\"geometry\", {}))\n",
    "            subtype = props.get(\"subtype\")\n",
    "\n",
    "            if subtype not in CLASS_MAPPING:\n",
    "                continue\n",
    "\n",
    "            class_id = CLASS_MAPPING[subtype]\n",
    "\n",
    "            geometries = [geom] if isinstance(geom, Polygon) else list(geom.geoms) if isinstance(geom, MultiPolygon) else []\n",
    "\n",
    "            for poly in geometries:\n",
    "                coords = list(poly.exterior.coords)\n",
    "                if len(coords) < 3:\n",
    "                    continue\n",
    "\n",
    "                norm_coords = []\n",
    "                for x, y in coords:\n",
    "                    x_norm = x / width\n",
    "                    y_norm = y / height\n",
    "                    norm_coords.append(f\"{x_norm:.6f} {y_norm:.6f}\")\n",
    "\n",
    "                label_line = f\"{class_id} \" + \" \".join(norm_coords)\n",
    "                label_lines.append(label_line)\n",
    "\n",
    "        if label_lines:\n",
    "            output_path = output_dir / f\"{base_stem}.txt\"\n",
    "            with open(output_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "print(\"\\nâœ… YOLO label conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f420ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Converting split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 214/214 [00:00<00:00, 450.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Converting split: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 534.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Converting split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 490.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… YOLO polygon label conversion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from shapely import wkt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "SOURCE_ROOT = Path(\"../data/data_primary/processed/split\")\n",
    "DEST_ROOT = Path(\"../data/data_primary_yolo\")\n",
    "CLASS_MAPPING = {\n",
    "    \"no-damage\": 1,\n",
    "    \"minor-damage\": 0,\n",
    "    \"major-damage\": 0,\n",
    "    \"destroyed\": 0,\n",
    "}\n",
    "IMAGE_EXTENSION = \".png\"\n",
    "\n",
    "# === Create Folder Structure ===\n",
    "for split in SPLITS:\n",
    "    (DEST_ROOT / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Main Conversion ===\n",
    "for split in SPLITS:\n",
    "    print(f\"\\nðŸ”„ Converting split: {split}\")\n",
    "    image_dir = SOURCE_ROOT / split / \"images\"\n",
    "    label_dir = SOURCE_ROOT / split / \"labels\"\n",
    "    output_dir = DEST_ROOT / \"labels\" / split\n",
    "\n",
    "    label_files = list(label_dir.glob(\"*.json\"))\n",
    "\n",
    "    for label_path in tqdm(label_files, desc=f\"{split}\"):\n",
    "        base_name = label_path.stem  # e.g. hurricane-florence_00000064_post_disaster\n",
    "        image_path = image_dir / f\"{base_name}{IMAGE_EXTENSION}\"\n",
    "        if not image_path.exists():\n",
    "            continue\n",
    "\n",
    "        # Get image dimensions\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        # Load and parse JSON\n",
    "        with open(label_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        features = data.get(\"features\", {}).get(\"xy\", [])\n",
    "        label_lines = []\n",
    "\n",
    "        for item in features:\n",
    "            subtype = item.get(\"properties\", {}).get(\"subtype\", \"no-damage\").strip().lower()\n",
    "            class_id = CLASS_MAPPING.get(subtype)\n",
    "            if class_id is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                polygon = wkt.loads(item[\"wkt\"])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if not polygon.is_valid or polygon.is_empty:\n",
    "                continue\n",
    "\n",
    "            coords = list(polygon.exterior.coords)\n",
    "            if len(coords) < 3:\n",
    "                continue\n",
    "\n",
    "            norm_coords = [\n",
    "                f\"{x / width:.6f} {y / height:.6f}\"\n",
    "                for x, y in coords\n",
    "            ]\n",
    "            yolo_line = f\"{class_id} \" + \" \".join(norm_coords)\n",
    "            label_lines.append(yolo_line)\n",
    "\n",
    "        # Write .txt file\n",
    "        if label_lines:\n",
    "            out_path = output_dir / f\"{base_name}.txt\"\n",
    "            with open(out_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(label_lines))\n",
    "\n",
    "print(\"\\nâœ… YOLO polygon label conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e7d66aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 776.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing split: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<00:00, 637.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 329.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "SOURCE_IMAGE_ROOT = Path(\"../data/data_primary/processed/split\")\n",
    "DEST_ROOT = Path(\"../data/data_primary_yolo\")\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\n Processing split: {split}\")\n",
    "    src_img_dir = SOURCE_IMAGE_ROOT / split / \"images\"\n",
    "    label_dir = DEST_ROOT / split / \"labels\"\n",
    "    dest_img_dir = DEST_ROOT / split / \"images\"\n",
    "\n",
    "    # Ensure image folder exists\n",
    "    dest_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    label_files = list(label_dir.glob(\"*.txt\"))\n",
    "\n",
    "    for label_file in tqdm(label_files, desc=f\"{split}\"):\n",
    "        base_name = label_file.stem\n",
    "        image_path = src_img_dir / f\"{base_name}.png\"\n",
    "\n",
    "        if image_path.exists():\n",
    "            shutil.copy(image_path, dest_img_dir / image_path.name)\n",
    "        else:\n",
    "            print(f\"Missing image for label: {base_name}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732ca6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbital_response",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
